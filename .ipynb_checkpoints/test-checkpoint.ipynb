{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8849,
     "status": "ok",
     "timestamp": 1614612199210,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "0hCAsRuLsMC-",
    "outputId": "da77ad4a-5c76-4c64-cb3f-d218a6cf551d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision, torch\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import tree\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8794,
     "status": "ok",
     "timestamp": 1614612199213,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "HXDoYOghyxmR"
   },
   "outputs": [],
   "source": [
    "def get_grayscale(path):\n",
    "\n",
    "    img = cv2.imread(path, 0)\n",
    "    img = cv2.resize(img, (256, 256), interpolation = cv2.INTER_CUBIC)\n",
    "    img = img.reshape(256, 256, 1, 1).astype(float) /255.0\n",
    "    img = torch.from_numpy(img).permute(3, 2, 0, 1).float()\n",
    "    return img\n",
    "\n",
    "# gray = get_grayscale('bgrtest/000000.jpg').detach().numpy().reshape((256, 256))\n",
    "# plt.imshow(gray, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8749,
     "status": "ok",
     "timestamp": 1614612199216,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "Yl_DRbI5XQ0L"
   },
   "outputs": [],
   "source": [
    "def get_ab(path):\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    img = cv2.resize(img, (256, 256), interpolation = cv2.INTER_CUBIC)\n",
    "    img = img.reshape(256, 256, 3).astype(float) / 255.0\n",
    "    img = img[:,:,1:]\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img\n",
    "\n",
    "# get_ab('bgrtest/000000.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8703,
     "status": "ok",
     "timestamp": 1614612199219,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "2ZkaZkSkYL2P"
   },
   "outputs": [],
   "source": [
    "def combine(l, ab):\n",
    "    img = np.concatenate((l, ab), axis = -1)\n",
    "    return img\n",
    "\n",
    "# l = np.random.rand(256, 256, 1)\n",
    "# ab = np.random.rand(256, 256, 2)\n",
    "# lab = combine(l, ab)\n",
    "# assert (lab[:, :, 1] == ab[:, :, 0]).all()\n",
    "# lab.shape\n",
    "# plt.imshow(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8654,
     "status": "ok",
     "timestamp": 1614612199222,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "pXUEhRiwCzmn"
   },
   "outputs": [],
   "source": [
    "class ImagesDatasetTest(Dataset):\n",
    "\n",
    "    def __init__(self, img_dir, transform = []):\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.img_files = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        self.path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        sz = cv2.imread(self.path, 0).shape\n",
    "        x = get_grayscale(self.path)\n",
    "\n",
    "        return x, idx, sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8604,
     "status": "ok",
     "timestamp": 1614612199225,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "TIBnGLNu88nu"
   },
   "outputs": [],
   "source": [
    "class ColorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorNet, self).__init__()\n",
    "    \n",
    "        def encode_layer(inp, out, kernel = 3, stride = 1, padding = 0, dilation = 1):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, out, kernel, stride, padding, dilation),\n",
    "                nn.BatchNorm2d(out),\n",
    "                nn.SELU(True)\n",
    "            )\n",
    "\n",
    "        def decode_layer(inp, out, kernel = 3, stride = 1, padding = 0):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(inp, out, kernel, stride, padding),\n",
    "                nn.BatchNorm2d(out),\n",
    "                nn.SELU(True)\n",
    "            )\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            encode_layer(1, 64),\n",
    "            encode_layer(64, 64),\n",
    "            encode_layer(64, 128),\n",
    "            encode_layer(128, 256),\n",
    "            encode_layer(256, 512)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            decode_layer(512, 256),\n",
    "            decode_layer(256, 128),\n",
    "            decode_layer(128, 64),\n",
    "            decode_layer(64, 32),\n",
    "            decode_layer(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9705,
     "status": "ok",
     "timestamp": 1614612200377,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "b28Biy91LLLy",
    "outputId": "aec0f21c-fa88-4fbf-a628-7776de8aaef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vHlcTqj8GzUIUY5NrjLlWWkEdpglR6BR\n",
      "To: /content/modelv2.pth\n",
      "12.7MB [00:00, 77.3MB/s]\n",
      "bgrtest  drive\tmodelv2.pth  sample_data\n"
     ]
    }
   ],
   "source": [
    "# link: https://drive.google.com/file/d/1vHlcTqj8GzUIUY5NrjLlWWkEdpglR6BR/view?usp=sharing\n",
    "!gdown --id 1vHlcTqj8GzUIUY5NrjLlWWkEdpglR6BR\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20185,
     "status": "ok",
     "timestamp": 1614612210912,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "ie1Ucx5BCwsa",
    "outputId": "c7f14785-e4c2-4a4d-84ad-3c8e1bce3b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColorNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(32, 2, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SELU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'modelv2.pth'\n",
    "model = ColorNet().to(device)\n",
    "model.load_state_dict(copy.deepcopy(torch.load(PATH, device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196746,
     "status": "ok",
     "timestamp": 1614612416163,
     "user": {
      "displayName": "Eklavya Jain",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh8SzevBzq0JHrcav9R3pAGjlqH1k4h8sp40d-7VvQ=s64",
      "userId": "15174312925382477648"
     },
     "user_tz": -330
    },
    "id": "ardQzwYxKNMQ",
    "outputId": "d1b21ea5-670a-4f1b-eca2-2b011eed7eb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4739.21060752058, 2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluationFunction(dataset):\n",
    "\n",
    "    image_names = list(os.listdir(dataset+\"input/\"))\n",
    "    predictions = {}\n",
    "    # image_names = os.listdir('bgrtest')[:2000]\n",
    "    for img in image_names:\n",
    "        file = dataset + 'input/' + img\n",
    "        file = 'bgrtest/'+img\n",
    "        h, w = cv2.imread(file, 0).shape\n",
    "\n",
    "        gray = get_grayscale(file).to(device)      \n",
    "        pred = model(gray)\n",
    "\n",
    "        pred = pred.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "        gray = gray.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "\n",
    "        lab = combine(gray, pred)[0]\n",
    "        lab = cv2.resize(lab, (w, h), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        predictions[img] = lab\n",
    "\n",
    "    score = 0\n",
    "    for img in image_names:\n",
    "        imgy = cv2.imread(dataset+\"groundtruth/\"+img)\n",
    "        # imgy = cv2.imread('bgrtest/'+img)\n",
    "        imgy = cv2.cvtColor(imgy,cv2.COLOR_BGR2Lab) # Covert ground truth to LAB; (OpenCV uses BGR by default)\n",
    "        imgy = np.asarray(imgy).astype('float32')\n",
    "        imgy /= 255.0\n",
    "\n",
    "        score += np.sum(np.power(imgy - predictions[img], 2)) # Find L2 loss\n",
    "\n",
    "    score /= len(image_names)\n",
    "\n",
    "    return score, len(image_names)\n",
    "\n",
    "# evaluationFunction('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpLoLhImVA8m"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTANT\n",
    "\n",
    "Following information has to be specified here as shown before submission\n",
    "\n",
    "Train dataset size used:  800 MB (12000 Images)\n",
    "Approx training time: 12 hours\n",
    "Number of Model parameters : 3 Million\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNQMAYooYPokL8s4UNHm0g2",
   "collapsed_sections": [],
   "mount_file_id": "1HPQ3-zbuZeX2CQWY654SnI6FLxCijY50",
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
